
#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
typedef float2 Complex;
typedef double2 ComplexDouble;
#define  dataSize  50*1000*1000


cudaError_t ReductionSumCuda(float*Input, float *Output, int SectionLen, int SectionNum);

__global__ void ReductionSum(float*Input, float *Output, int SectionLen, int SectionNum)
{
	Output[blockIdx.x] = 0;
	__shared__ float  InputData[1024];

	if (blockIdx.x < SectionNum)
	{
		for (int i = 0; i < SectionLen; i += 1024)
		{
			if (i + threadIdx.x < SectionLen)
			{
				InputData[threadIdx.x] = Input[blockIdx.x*SectionLen + i + threadIdx.x];

				int j = 512;

				while (j != 0)
				{
					if (threadIdx.x < j)
					{
						InputData[threadIdx.x] += InputData[threadIdx.x + j];

					}
					__syncthreads();
					j /= 2;
				}

				if (threadIdx.x == 0)
				{
					Output[blockIdx.x] = Output[blockIdx.x] + InputData[0];
				}

				InputData[threadIdx.x] = 0;

			}
		}
	}
}

int main()
{
	int SectionLen = 5000;
	int SectionNum = dataSize / SectionLen;
	float *input = (float*)malloc(sizeof(float)*dataSize);
	float *output = (float*)malloc(sizeof(float)*dataSize);
	// 设置随机数种子
	srand((unsigned int)time(NULL));

	for (int i = 0; i < dataSize; i++) {

		//input[i] = (float)(rand() % 10); // 假设生成0到9之间的随机数
		input[i] =1;
	}

	  
	cudaError_t cudaStatus = ReductionSumCuda(input,  output, SectionLen, SectionNum);
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "sumWithCuda failed!");
		return 1;
	}

	printf("执行成功\n");

	// cudaDeviceReset must be called before exiting in order for profiling and
	// tracing tools such as Nsight and Visual Profiler to show complete traces.
	cudaStatus = cudaDeviceReset();
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaDeviceReset failed!");
		return 1;
	}

	return 0;
}

// Helper function for using CUDA  
cudaError_t ReductionSumCuda(float *Input, float *Output, int  SectionLen,int SectionNum)
{
	float *dev_input = 0;
	float *dev_output = 0;
	cudaError_t cudaStatus;

	// Choose which GPU to run on, change this on a multi-GPU system.
	cudaStatus = cudaSetDevice(0);
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaSetDevice failed!  Do you have a CUDA-capable GPU installed?");
		goto Error;
	}

 
	cudaStatus = cudaMalloc((void**)&dev_input, dataSize * sizeof(float));
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaMalloc failed!");
		goto Error;
	}



	cudaStatus = cudaMalloc((void**)&dev_output, dataSize * sizeof(float));
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaMalloc failed!");
		goto Error;
	}


	// Copy input vectors from host memory to GPU buffers.
	cudaStatus = cudaMemcpy(dev_input, Input, dataSize * sizeof(float), cudaMemcpyHostToDevice);
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaMemcpy failed!");
		goto Error;
	}

	// Launch a kernel on the GPU  
	ReductionSum << <SectionNum, 1024 >> > (dev_input,  dev_output, SectionLen, SectionNum);

	// Check for any errors launching the kernel
	cudaStatus = cudaGetLastError();
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "addKernel launch failed: %s\n", cudaGetErrorString(cudaStatus));
		goto Error;
	}

	// cudaDeviceSynchronize waits for the kernel to finish, and returns
	// any errors encountered during the launch.
	cudaStatus = cudaDeviceSynchronize();
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaDeviceSynchronize returned error code %d after launching addKernel!\n", cudaStatus);
		goto Error;
	}

	// Copy output vector from GPU buffer to host memory.
	cudaStatus = cudaMemcpy(Output, dev_output, dataSize * sizeof(float), cudaMemcpyDeviceToHost);
	if (cudaStatus != cudaSuccess) {
		fprintf(stderr, "cudaMemcpy failed!");
		goto Error;
	}

Error:
	cudaFree(dev_input);
	cudaFree(dev_output);
	return cudaStatus;
}
